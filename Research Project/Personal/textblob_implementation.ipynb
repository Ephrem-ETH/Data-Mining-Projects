{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn import *\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataClean(tweets_raw):\n",
    "    cleanTweets = []\n",
    "    for tweet in tweets_raw:\n",
    "        tweet = tweet.lower() #convert to lowercase\n",
    "        tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet) #remove URL\n",
    "        tweet = re.sub(r'(\\s)@\\w+', r'', tweet) #remove usernames\n",
    "        tweet = re.sub(r'@\\w+', r'', tweet) #remove usernames\n",
    "        tweet = re.sub('<[^<]+?>', '', tweet) #remove HTML tags\n",
    "        tweet = re.sub(r'[<>!#@$:.,%\\?-]+', r'', tweet) #remove punctuation and special characters \n",
    "        lower_case = tweet.lower() #tokenization \n",
    "        words = lower_case.split()\n",
    "        tweet = ' '.join([w for w in words if not w in nltk.corpus.stopwords.words(\"english\")]) #remove stopwords\n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        stemmedTweet = [ps.stem(word) for word in tweet.split(\" \")]\n",
    "        stemmedTweet = \" \".join(stemmedTweet)\n",
    "        tweet = str(stemmedTweet)\n",
    "        tweet = tweet.replace(\"'\", \"\")\n",
    "        tweet = tweet.replace(\"\\\"\",\"\")\n",
    "        cleanTweets.append(tweet)\n",
    "    return cleanTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingFile = \"train.xlsx\"\n",
    "df_obama = pd.read_excel(trainingFile,sheetname='Obama')\n",
    "df_romney = pd.read_excel(trainingFile,sheetname='Romney')\n",
    "\n",
    "#Removing the mixed class and the !!! class\n",
    "\n",
    "df_obama = df_obama[(df_obama['Class'].isin((1,-1)))]\n",
    "df_romney = df_romney[(df_romney['Class'].isin((1,-1)))]\n",
    "\n",
    "#creating lists for raw tweets and classes\n",
    "\n",
    "obama_tweets_raw = df_obama['Anootated tweet']\n",
    "obama_class = df_obama['Class']\n",
    "romney_tweets_raw = df_romney['Anootated tweet']\n",
    "romney_class = df_romney['Class']\n",
    "\n",
    "obama_tweets_raw = obama_tweets_raw.tolist()\n",
    "romney_tweets_raw = romney_tweets_raw.tolist()\n",
    "obama_class_train = obama_class.tolist()\n",
    "romney_class_train = romney_class.tolist()\n",
    "\n",
    "romney_tweets = dataClean(romney_tweets_raw) #romney tweets cleaning\n",
    "obama_tweets = dataClean(obama_tweets_raw) #obama tweets cleaning\n",
    "\n",
    "obama_merged = zip(obama_tweets, obama_class_train)\n",
    "obama_merged = list(obama_merged)\n",
    "\n",
    "romney_merged = zip(romney_tweets, romney_class_train)\n",
    "romney_merged = list(romney_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = NaiveBayesClassifier(obama_merged)\n",
    "c2 = NaiveBayesClassifier(romney_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testingFile = \"test.xlsx\"\n",
    "df_obama_test = pd.read_excel(testingFile,sheetname='Obama')\n",
    "df_romney_test = pd.read_excel(testingFile,sheetname='Romney')\n",
    "\n",
    "#Removing the mixed class and the !!! class\n",
    "\n",
    "df_obama_test = df_obama_test[(df_obama_test['Class'].isin((1,-1)))]\n",
    "df_romney_test = df_romney_test[(df_romney_test['Class'].isin((1,-1)))]\n",
    "\n",
    "#creating lists for raw tweets and classes\n",
    "\n",
    "obama_tweets_raw_test = df_obama_test['Anootated tweet']\n",
    "obama_class_test = df_obama_test['Class']\n",
    "romney_tweets_raw_test = df_romney_test['Anootated tweet']\n",
    "romney_class_test = df_romney_test['Class']\n",
    "\n",
    "obama_tweets_raw_test = obama_tweets_raw_test.tolist()\n",
    "romney_tweets_raw_test = romney_tweets_raw_test.tolist()\n",
    "obama_class_test = obama_class_test.tolist()\n",
    "romney_class_test = romney_class_test.tolist()\n",
    "\n",
    "romney_tweets_test = dataClean(romney_tweets_raw_test) #romney tweets cleaning\n",
    "obama_tweets_test = dataClean(obama_tweets_raw_test) #obama tweets cleaning\n",
    "\n",
    "obama_merged_test = zip(obama_tweets_test, obama_class_test)\n",
    "obama_merged_test = list(obama_merged_test)\n",
    "\n",
    "romney_merged_test = zip(romney_tweets_test, romney_class_test)\n",
    "romney_merged_test = list(romney_merged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_obama = []\n",
    "for each in obama_merged_test:\n",
    "    temp = c1.classify(str(each))\n",
    "    pred_obama.append(temp)\n",
    "\n",
    "pred_romney = []\n",
    "for each in romney_merged_test:\n",
    "    temp = c2.classify(str(each))\n",
    "    pred_romney.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama: \n",
      "Overall Acurracy:  0.725984251969 \n",
      "\n",
      "Precision of positive class: 0.687500\n",
      "Recall of positive class: 0.737113\n",
      "F1-Score of positive class: 0.711443 \n",
      "\n",
      "Precision of negative class: 0.763158\n",
      "Recall of negative class: 0.716570\n",
      "F1-Score of negative class: 0.739130 \n",
      "\n",
      "Romney:\n",
      "Overall Acurracy:  0.776208178439 \n",
      "\n",
      "Precision of positive class: 0.677966\n",
      "Recall of positive class: 0.415584\n",
      "F1-Score of positive class: 0.515298 \n",
      "\n",
      "Precision of negative class: 0.797115\n",
      "Recall of negative class: 0.920833\n",
      "F1-Score of negative class: 0.854519 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obama\n",
    "accScore = metrics.accuracy_score(obama_class_test,pred_obama)\n",
    "labels = [1,-1]\n",
    "precision = metrics.precision_score(obama_class_test,pred_obama,average=None,labels=labels)\n",
    "recall = metrics.recall_score(obama_class_test,pred_obama,average=None,labels=labels)\n",
    "f1Score = metrics.f1_score(obama_class_test,pred_obama,average=None,labels=labels)\n",
    "print(\"Obama: \\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "lbl = ['positive', 'negative']\n",
    "for i in range(2):\n",
    "    print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
    "    print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
    "    print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\")\n",
    "#romney\n",
    "accScore = metrics.accuracy_score(romney_class_test,pred_romney)\n",
    "precision = metrics.precision_score(romney_class_test,pred_romney,average=None,labels=labels)\n",
    "recall = metrics.recall_score(romney_class_test,pred_romney,average=None,labels=labels)\n",
    "f1Score = metrics.f1_score(romney_class_test,pred_romney,average=None,labels=labels)\n",
    "print(\"Romney:\\nOverall Acurracy: \",accScore,\"\\n\")\n",
    "for i in range(2):\n",
    "    print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
    "    print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
    "    print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
